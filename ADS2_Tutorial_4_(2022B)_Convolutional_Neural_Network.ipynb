{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebereinyiama/ADS-Assignment1/blob/main/ADS2_Tutorial_4_(2022B)_Convolutional_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFn01UrTj1YS"
      },
      "source": [
        "# Tutorial 4 - Convolutional Neural Networks\n",
        "\n",
        "In this tutorial, we will build a convolutional neural network for predicting the label of images which contain handwritten digits. The MNIST dataset is a widely used benchmarking dataset in the ML community, and consists of 70,000, 28x28 pixel images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb2HPdzPjO3I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee1089e9-4a0d-4df3-e134-047cd1a921d7"
      },
      "source": [
        "# Import tensorflow and load the MNIST image dataset\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Dataset is split into 60,000 training images and 10,000 testing images\n",
        "# Each image is given a label from (0,9), corresponding to the class\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.\\\n",
        "                                                mnist.load_data()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1\n",
        "\n",
        "Check the data by plotting some of the images, using their class labels as image titles. Use subplots to display 10 of the images from the training set.\n",
        "\n",
        "Convert the images to `dtype=\"float32\"` and scale the pixels to a range of (0,255)."
      ],
      "metadata": {
        "id": "RbgQeV0B4ZeS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZfOGI37nB-O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "46f2bc46-bd8c-4c96-a084-5882a041d260"
      },
      "source": [
        "### Plot 10 of the training images in a (2,5) grid of subplots\n",
        "### Use the image labels as titles on the subplots\n",
        "# plt.subplots, axis.imshow, axis.set_title\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, ax = plt.subplots(2, 5, figsize=(10,4))\n",
        "ax = ax.flatten()\n",
        "\n",
        "for i in range(10):\n",
        "  ax[i].imshow(x_train[i,:,:])\n",
        "  ax[i].set_title(f'Label = {y_train[i]}') #prints the labels\n",
        "  ax[i].set_xticks([])\n",
        "  ax[i].set_yticks([])\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLh69IDQns2M"
      },
      "source": [
        "### Convert the images to floats and scale the pixel to a range of\n",
        "### (0,1). Reshape the images to shape (-1, 28, 28, 1).\n",
        "# array.astype, np.reshape\n",
        "\n",
        "x_train = np.reshape(x_train.astype('float32'), (-1, 28, 28, 1))/255.\n",
        "x_test = np.reshape(x_test.astype('float32'), (-1, 28, 28, 1))/255."
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAk9cmUTrWVT"
      },
      "source": [
        "# Exercise 2\n",
        "\n",
        "A Convolutional Neural Network utilises convolutional layers to identify salient features within images—such as edges, curves, changes in brightness. Complete the following Keras Seuqential model so that it has these layers:\n",
        "\n",
        "```\n",
        "Input Layer - Shape = (28,28,1), dtype='float32'\n",
        "Convoltuonal Layer - 32 filters, (1,1) stride, (3,3) kernel, 'relu' activation, 'same' padding\n",
        "Max Pooling Layer - (2,2) pool size\n",
        "Convoltuonal Layer - 32 filters, (1,1) stride, (3,3) kernel, 'relu' activation, 'same' padding\n",
        "Max Pooling Layer - (2,2) pool size\n",
        "Flattent Layer\n",
        "Dense Layer - 64 units, 'relu' activation\n",
        "Dense Layer - 10 units\n",
        "```\n",
        "\n",
        "Print the model summary.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Create the layers for the CNN model, using the Functional API\n",
        "# Input, Conv2D, MaxPool2D, Flatten, Dense\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "Inp = layers.Input((28,28,1), dtype='float32', name='Model_Input')\n",
        "Conv1 = layers.Conv2D(32, (3,3), activation='relu',\n",
        "                      padding='same', name='conv_1')(Inp)\n",
        "Pool1 = layers.MaxPool2D(pool_size=(2,2),\n",
        "                         name='pool_1')(Conv1)\n",
        "Conv2 = layers.Conv2D(32, (3,3), activation='relu',\n",
        "                      padding='same', name='conv_2')(Pool1)\n",
        "Pool2 = layers.MaxPool2D(pool_size=(2,2),\n",
        "                         name='pool_2')(Conv2)\n",
        "Flat = layers.Flatten()(Pool2)\n",
        "Dense1 = layers.Dense(64, activation='relu', name='fc_1')(Flat)\n",
        "Dense2 = layers.Dense(10, name='fc_2')(Dense1)\n",
        "\n"
      ],
      "metadata": {
        "id": "izoOK1_b5fkR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Create the model, using the input and output tensors you have define above.\n",
        "# models.Model\n",
        "\n",
        "mnist_model = models.Model(inputs=Inp, outputs=Dense2)\n",
        "mnist_model.summary()"
      ],
      "metadata": {
        "id": "jiO_5Wd7Wh8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f39992f-4270-4ccd-8266-af8c3bfa6e76"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Model_Input (InputLayer)    [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv_1 (Conv2D)             (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " pool_1 (MaxPooling2D)       (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " conv_2 (Conv2D)             (None, 14, 14, 32)        9248      \n",
            "                                                                 \n",
            " pool_2 (MaxPooling2D)       (None, 7, 7, 32)          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1568)              0         \n",
            "                                                                 \n",
            " fc_1 (Dense)                (None, 64)                100416    \n",
            "                                                                 \n",
            " fc_2 (Dense)                (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 110,634\n",
            "Trainable params: 110,634\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3\n",
        "\n",
        "Now we must prepare the model for training. Compile the model using the Adam Optimizer, Sparse Categorical Crossentropy loss `(from_logits=True)`, and the accuracy metric."
      ],
      "metadata": {
        "id": "hrehA_em-fVW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-1gZgTc3Hxw"
      },
      "source": [
        "### Compile the model with the Adam optimizer, Sparse Categorical Crossentropy\n",
        "### loss (from_logits=True), and the accuracy metric\n",
        "# optimizers.Adam, losses.SparseCategoricalCrossentropy\n",
        "from tensorflow.keras import losses, optimizers\n",
        "\n",
        "mnist_model.compile(optimizer=optimizers.Adam(), loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4\n",
        "\n",
        "Train the model on the training data using the `.fit` method. Train for 25 epochs. Use the testing data for validation. Store the losses and metrics in the history object.\n",
        "\n",
        "Plot the losses and metrics for the training and validation data. What do these plots tell us about the model performance? Why is the model better at classifying the training images? Has the model reached an optimal solution?"
      ],
      "metadata": {
        "id": "b3ITrF-SAs7p"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWMt1lp576xW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda7b499-e67c-4abd-957e-9fe5cbd9854b"
      },
      "source": [
        "### Train the model for 25 epochs on the training images and labels\n",
        "### Using the test images and labels as validation data\n",
        "\n",
        "history = mnist_model.fit(x=x_train, y=y_train, epochs=25, validation_data=(x_test, y_test), batch_size=512)\n",
        "\n",
        "# Keys inside the history dictionary.\n",
        "print(history.history.keys)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "118/118 [==============================] - 85s 702ms/step - loss: 0.5259 - accuracy: 0.8531 - val_loss: 0.1494 - val_accuracy: 0.9526\n",
            "Epoch 2/25\n",
            "118/118 [==============================] - 73s 622ms/step - loss: 0.1184 - accuracy: 0.9646 - val_loss: 0.0767 - val_accuracy: 0.9768\n",
            "Epoch 3/25\n",
            "118/118 [==============================] - 63s 539ms/step - loss: 0.0776 - accuracy: 0.9765 - val_loss: 0.0567 - val_accuracy: 0.9813\n",
            "Epoch 4/25\n",
            "118/118 [==============================] - 61s 517ms/step - loss: 0.0591 - accuracy: 0.9826 - val_loss: 0.0466 - val_accuracy: 0.9852\n",
            "Epoch 5/25\n",
            "118/118 [==============================] - 64s 546ms/step - loss: 0.0514 - accuracy: 0.9842 - val_loss: 0.0420 - val_accuracy: 0.9855\n",
            "Epoch 6/25\n",
            "118/118 [==============================] - 73s 618ms/step - loss: 0.0429 - accuracy: 0.9870 - val_loss: 0.0443 - val_accuracy: 0.9854\n",
            "Epoch 7/25\n",
            "118/118 [==============================] - 87s 739ms/step - loss: 0.0381 - accuracy: 0.9884 - val_loss: 0.0343 - val_accuracy: 0.9878\n",
            "Epoch 8/25\n",
            "118/118 [==============================] - 81s 685ms/step - loss: 0.0330 - accuracy: 0.9896 - val_loss: 0.0351 - val_accuracy: 0.9880\n",
            "Epoch 9/25\n",
            "118/118 [==============================] - 69s 582ms/step - loss: 0.0305 - accuracy: 0.9902 - val_loss: 0.0397 - val_accuracy: 0.9867\n",
            "Epoch 10/25\n",
            "118/118 [==============================] - 64s 542ms/step - loss: 0.0274 - accuracy: 0.9918 - val_loss: 0.0456 - val_accuracy: 0.9849\n",
            "Epoch 11/25\n",
            "118/118 [==============================] - 62s 523ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.0379 - val_accuracy: 0.9880\n",
            "Epoch 12/25\n",
            "118/118 [==============================] - 63s 530ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.0333 - val_accuracy: 0.9893\n",
            "Epoch 13/25\n",
            "118/118 [==============================] - 75s 633ms/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 0.0307 - val_accuracy: 0.9899\n",
            "Epoch 14/25\n",
            "118/118 [==============================] - 61s 518ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0355 - val_accuracy: 0.9879\n",
            "Epoch 15/25\n",
            "  4/118 [>.............................] - ETA: 49s - loss: 0.0109 - accuracy: 0.9971"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Plot the losses and metrics for the training and validation data.\n",
        "### These values are stored inside the history.history dictionary object.\n",
        "### You should make two plots, one for the losses, and one for the metrics.\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label = 'Training')\n",
        "plt.plot(history.history['val_loss'], label = 'Validation')\n",
        "plt.legend(loc=0)\n",
        "plt.title('Model Loss')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'], label = 'Training')\n",
        "plt.plot(history.history['val_accuracy'], label = 'Validation')\n",
        "plt.legend(loc=0)\n",
        "plt.title('Model Accuracy')\n"
      ],
      "metadata": {
        "id": "1OzA1nBFXdsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2EL3e8tVLcL"
      },
      "source": [
        "# Exercise 5\n",
        "\n",
        "Currently, the output of our model is in the form of \"logits\", these are raw predictions that we can map to a probability for each of the 10 classes in our data. To do so, create a sequential model, where the first layer is the model you just trained—models can in fact be treated as layers in a higher level model—and the second layer is ```layers.Softmax()```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M8sFVIfV4F5"
      },
      "source": [
        "### Add a softmax activation layer by creating a new seuqential model that\n",
        "### takes the original model as the first layer in the list\n",
        "# models.Sequential, layers.Softmax\n",
        "import numpy as np\n",
        "\n",
        "prediction_model = models.Sequential([mnist_model, layers.Softmax()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGufQuzhWsAq"
      },
      "source": [
        "The output of the model is now a 10-element vector for each image, which represents the probability distribution of the class labels.\n",
        "\n",
        "Use the `.predict` method to calculate the probabilities of the images in the test sample.\n",
        "\n",
        "Use the numpy function `argmax()` to find the highest probability class for the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAF6qKOMWtZ_"
      },
      "source": [
        "### Use the .predict method to find the probabilities of each test image being\n",
        "### within each of the 10 classes. Then find the highest probability class for\n",
        "### each test image\n",
        "# .predict, np.argmax\n",
        "\n",
        "y_pred = prediction_model.predict(x_test)\n",
        "y_pred_label = np.argmax(y_pred, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 6\n",
        "\n",
        "Create a plot which displays images in a (5,5) grid, and show the ground truth and predicted class labels for each image as a title. (Extra challenge, choose the images at random, not in the order of the test set. Extra EXTRA challenge, create plots which have only images that are correctly or incorrectly predicted.)"
      ],
      "metadata": {
        "id": "waN0sKBbQbjq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPJhI4ODZYdd"
      },
      "source": [
        "### Create a plot which displays images in a (5,5) grid, and show the ground\n",
        "### truth and predicted class labels for each image as a title.\n",
        "\n",
        "f, ax = plt.subplots(5, 5, figsize=(10,12))\n",
        "ax = ax.flatten()\n",
        "\n",
        "for i in range(25):\n",
        "  ax[i].imshow(x_test[i,:,:,0])\n",
        "  ax[i].set_title(f'Truth = {y_test[i]}\\nPred = {y_pred_label[i]}') #prints the labels\n",
        "  ax[i].set_xticks([])\n",
        "  ax[i].set_yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}